import streamlit as st
from utils import print_messages, StreamHandler, generate_summary, text_to_speech, autoplay_audio
from langchain_community.chat_message_histories.streamlit import StreamlitChatMessageHistory
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.messages import ChatMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai import ChatOpenAI
import os
import uuid
import requests

# ìŠ¤íŠ¸ë¦¼ë¦¿ ì•±ì˜ ê¸°ë³¸ ì„¤ì •
st.set_page_config(page_title="Voice Chat App", page_icon="ğŸ¤–")
st.title('í‹°ì²˜ë¸” ëŸ¬ì‹ ë¨¸ë‹ ê¸°ë°˜ğŸ¤” ë³´ì´ìŠ¤ì±—ğŸ™ï¸')

# OpenAI API í‚¤ ì„¤ì •
os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state["messages"] = []
if "store" not in st.session_state:
    st.session_state["store"] = {}
if "chat_ids" not in st.session_state:
    st.session_state["chat_ids"] = []
if "chat_titles" not in st.session_state:
    st.session_state["chat_titles"] = {}
if "llm" not in st.session_state:
    st.session_state["llm"] = ChatOpenAI(streaming=True, callbacks=[
                                         StreamHandler(st.empty())], max_tokens=50, temperature=0.3)
if "prompt" not in st.session_state:
    st.session_state["prompt"] = ChatPromptTemplate.from_messages([
        ("system", "You recognise the person in the photo you uploaded as the person you're talking to, and you always call them by their first name, just like a friend."),
        MessagesPlaceholder(variable_name="history"),
        ("human", "{question}"),
    ])


def start_new_chat():
    if st.session_state["messages"]:
        summary = generate_summary(st.session_state["messages"])
        save_chat_history(summary)
    st.session_state["messages"] = []


def save_chat_history(summary=None):
    if not st.session_state["messages"]:
        st.warning("ì €ì¥í•  ëŒ€í™”ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    chat_id = str(uuid.uuid4())
    title = summary if summary else f"ëŒ€í™” {chat_id[:8]}"
    st.session_state["chat_titles"][chat_id] = title
    st.session_state["store"][chat_id] = st.session_state["messages"]
    st.session_state["chat_ids"].append(chat_id)
    st.session_state["messages"] = []


def load_chat_history(chat_id):
    if chat_id in st.session_state["store"]:
        st.session_state["messages"] = st.session_state["store"][chat_id]


def get_session_history(session_ids: str) -> BaseChatMessageHistory:
    if session_ids not in st.session_state["store"]:
        st.session_state["store"][session_ids] = StreamlitChatMessageHistory()
    return st.session_state["store"][session_ids]


# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    if st.sidebar.button("ìƒˆ ëŒ€í™” ì‹œì‘"):
        start_new_chat()
    chat_history_list = st.selectbox(
        "ëŒ€í™” ëª©ë¡",
        options=st.session_state["chat_ids"],
        format_func=lambda x: st.session_state["chat_titles"][x],
        key="chat_history_list"
    )
    col1, col2 = st.columns(2)
    with col1:
        if st.button("ëŒ€í™” ë¶ˆëŸ¬ì˜¤ê¸°"):
            load_chat_history(chat_history_list)
    with col2:
        if st.button("ëŒ€í™” ì €ì¥"):
            if st.session_state["messages"]:
                summary = generate_summary(st.session_state["messages"])
                save_chat_history(summary)
            else:
                st.warning("ì €ì¥í•  ëŒ€í™”ê°€ ì—†ìŠµë‹ˆë‹¤.")

    tts_models = ["alloy", "echo", "fable", "onyx", "nova", "shimmer"]
    tts_model = st.selectbox("ìŒì„±ì„ íƒ", tts_models)
    selected_speed = st.slider(
        "ë§í•˜ê¸° ì†ë„", min_value=0.5, max_value=2.0, value=1.0, step=0.1)

    st.sidebar.markdown("---")

    st.sidebar.header("ì‚¬ì§„ ì´¬ì˜")
    use_webcam = st.checkbox("ì›¹ìº  ì‚¬ìš©")

    if use_webcam:
        picture = st.camera_input("ì›¹ìº ì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ì§„ì„ ì°ìœ¼ì„¸ìš”")
        # ì›¹ìº ì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ì§„ì„ ì°ì—ˆì„ ë•Œì˜ ì²˜ë¦¬ ì¶”ê°€
        if use_webcam and picture:
            st.image(picture)
            files = {"file": ("webcam_image.png",
                              picture.getvalue(), "image/png")}
            response = requests.post(
                "http://127.0.0.1:8000/predict/", files=files)
            if response.status_code == 200:
                result = response.json()
                st.write(f"Class: {result['class']}")
                st.write(f"Confidence Score: {result['confidence_score']}")
                chain_with_memory = RunnableWithMessageHistory(
                    st.session_state["prompt"] | st.session_state["llm"], get_session_history, input_messages_key="question", history_messages_key="history")
                response = chain_with_memory.invoke({"question": f"ì‚¬ì§„ì„ ì—…ë¡œë“œí–ˆìŠµë‹ˆë‹¤: {result['class']}"}, config={
                                                    "configurable": {"session_id": str(uuid.uuid4())}})
                st.session_state["messages"].append(ChatMessage(
                    role="assistant", content=response.content))
                st.chat_message("assistant").write(response.content)
                speech_file_path = text_to_speech(
                    response.content, voice=tts_model, speed=selected_speed)
                autoplay_audio(speech_file_path)
            else:
                st.write("Error: Unable to get prediction")

    st.sidebar.header("ì´ë¯¸ì§€ ì—…ë¡œë“œ")
    uploaded_image = st.file_uploader(
        "ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["png", "jpg", "jpeg"])
    if uploaded_image is not None:
        st.image(uploaded_image, caption='Uploaded Image.',
                 use_column_width=True)
        files = {"file": (uploaded_image.name,
                          uploaded_image.getvalue(), uploaded_image.type)}
        response = requests.post("http://127.0.0.1:8000/predict/", files=files)
        if response.status_code == 200:
            result = response.json()
            st.write(f"Class: {result['class']}")
            st.write(f"Confidence Score: {result['confidence_score']}")
            chain_with_memory = RunnableWithMessageHistory(
                st.session_state["prompt"] | st.session_state["llm"], get_session_history, input_messages_key="question", history_messages_key="history")
            response = chain_with_memory.invoke({"question": f"ì‚¬ì§„ì„ ì—…ë¡œë“œí–ˆìŠµë‹ˆë‹¤: {result['class']}"}, config={
                                                "configurable": {"session_id": str(uuid.uuid4())}})
            st.session_state["messages"].append(ChatMessage(
                role="assistant", content=response.content))
            st.chat_message("assistant").write(response.content)
            speech_file_path = text_to_speech(
                response.content, voice=tts_model, speed=selected_speed)
            autoplay_audio(speech_file_path)
        else:
            st.write("Error: Unable to get prediction")

# ì´ì „ ëŒ€í™”ê¸°ë¡ ì¶œë ¥
print_messages()

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if user_input := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”"):
    st.chat_message("user").write(f"{user_input}")
    st.session_state["messages"].append(
        ChatMessage(role="user", content=user_input))
    chain_with_memory = RunnableWithMessageHistory(
        st.session_state["prompt"] | st.session_state["llm"], get_session_history, input_messages_key="question", history_messages_key="history")
    response = chain_with_memory.invoke({"question": user_input}, config={
                                        "configurable": {"session_id": str(uuid.uuid4())}})
    st.session_state["messages"].append(ChatMessage(
        role="assistant", content=response.content))
    st.chat_message("assistant").write(response.content)
    speech_file_path = text_to_speech(
        response.content, voice=tts_model, speed=selected_speed)
    autoplay_audio(speech_file_path)
